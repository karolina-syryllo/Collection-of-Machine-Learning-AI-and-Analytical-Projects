{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdnsT8VYCSYF"
   },
   "source": [
    "## COMP5623 Coursework on Image Classification with Convolutional Neural Networks \n",
    "\n",
    "Starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKS20wjsCSYI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from  torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpRGGlofCSYM"
   },
   "source": [
    "### Filter Visualization\n",
    "\n",
    "The first part of the assignment is to build a CNN and train it on a subset of the ImageNet dataset. We will first create a dataframe with all the references to the images and their labels.\n",
    "\n",
    "To download the images into your work environment, clone into a git respository containing the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyRlGy_e2rcJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "EqhQboSCCSYN",
    "outputId": "21bdf395-0c5d-48d9-b952-5c2fbe6ee07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'imagenet10' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/MohammedAlghamdi/imagenet10.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8edZnYShg7M1"
   },
   "source": [
    "Check that the repository is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "i2RIZGHaCVAC",
    "outputId": "3c100cd2-9104-441a-dab5-c4c82c207247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet10  sample_data\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47tv-wIQCTcS"
   },
   "outputs": [],
   "source": [
    "root_dir = \"imagenet10/train_set/\"\n",
    "class_names = [\n",
    "  \"baboon\",\n",
    "  \"banana\",\n",
    "  \"canoe\",\n",
    "  \"cat\",\n",
    "  \"desk\",\n",
    "  \"drill\",\n",
    "  \"dumbbell\",\n",
    "  \"football\",\n",
    "  \"mug\",\n",
    "  \"orange\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6oMdWl5CSYR"
   },
   "source": [
    "A helper function for reading in images and assigning labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQfcD3jyCSYT"
   },
   "outputs": [],
   "source": [
    "def get_meta(root_dir, dirs):\n",
    "    paths, classes = [], []\n",
    "    for i, dir_ in enumerate(dirs):\n",
    "        for entry in os.scandir(root_dir + dir_):\n",
    "            if (entry.is_file()):\n",
    "                paths.append(entry.path)\n",
    "                classes.append(i)\n",
    "                \n",
    "    return paths, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0J967KW0CSYX"
   },
   "source": [
    "Now we create a dataframe using all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gDPs1NCCSYY"
   },
   "outputs": [],
   "source": [
    "\n",
    "paths, classes = get_meta(root_dir, class_names)\n",
    "\n",
    "data = {\n",
    "    'path': paths,\n",
    "    'class': classes\n",
    "}\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['path', 'class'])\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True) # that shuffles the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRUDj3WihItY"
   },
   "source": [
    "View some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "mK2GPzfVCSYc",
    "outputId": "0d595a86-7dfc-4cce-f65a-4a02b512d494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagenet10/train_set/banana/n07753592_787.JPEG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagenet10/train_set/drill/n03239726_1895.JPEG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagenet10/train_set/mug/n03797390_7000.JPEG</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imagenet10/train_set/baboon/n02486410_3255.JPEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagenet10/train_set/baboon/n02486410_3715.JPEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path  class\n",
       "0   imagenet10/train_set/banana/n07753592_787.JPEG      1\n",
       "1   imagenet10/train_set/drill/n03239726_1895.JPEG      5\n",
       "2     imagenet10/train_set/mug/n03797390_7000.JPEG      8\n",
       "3  imagenet10/train_set/baboon/n02486410_3255.JPEG      0\n",
       "4  imagenet10/train_set/baboon/n02486410_3715.JPEG      0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Found\", len(data_df), \"images.\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai3uvziWCSYh"
   },
   "source": [
    "Now we will create the Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyUb-rzQCSYi"
   },
   "outputs": [],
   "source": [
    "class ImageNet10(Dataset):\n",
    "    \"\"\" ImageNet10 dataset. \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Directory with all the images\n",
    "            df (DataFrame object): Dataframe containing the images, paths and classes\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = Image.open(self.df['path'][index])\n",
    "        try:\n",
    "          x = x.convert('RGB') \n",
    "        except:\n",
    "          pass\n",
    "        y = torch.tensor(int(self.df['class'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqtRjBozCSYk"
   },
   "source": [
    "Compute what we should normalise the dataset to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPqfMPuZCSYl"
   },
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means, stdevs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_1KSGUe4sEW"
   },
   "outputs": [],
   "source": [
    "# saving mean and std as variable to save time\n",
    "norm_mean = [0.5228375, 0.4798797, 0.40604797]\n",
    "norm_std = [0.2977067, 0.28883943, 0.31178203]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqrG3FCUCSYo"
   },
   "source": [
    "We now create the transforms to normalise and turn our data into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVeZpgM-CSYq"
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean, norm_std),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAPzCfr2CSYt"
   },
   "source": [
    "Splitting data  into training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POCexxXjCSYu"
   },
   "outputs": [],
   "source": [
    "train_split = 0.70 # Defines the ratio of train/valid/test data.\n",
    "valid_split = 0.10\n",
    "\n",
    "train_size = int(len(data_df)*train_split)\n",
    "valid_size = int(len(data_df)*valid_split)\n",
    "\n",
    "ins_dataset_train = ImageNet10(\n",
    "    df=data_df[:train_size],\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "ins_dataset_valid = ImageNet10(\n",
    "    df=data_df[train_size:(train_size + valid_size)].reset_index(drop=True),\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "ins_dataset_test = ImageNet10(\n",
    "    df=data_df[(train_size + valid_size):].reset_index(drop=True),\n",
    "    transform=data_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "PzVfNzvmhTGJ"
   },
   "source": [
    "Creating Data Loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_womtSmIhgSj"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ins_dataset_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    ins_dataset_valid,\n",
    "    batch_size=24, \n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    ins_dataset_test,\n",
    "    batch_size=24, \n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "classes = np.arange(0, 10)\n",
    "#len(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X00vuzPWhY5h"
   },
   "source": [
    "ConvNet model: Experiments with number of layers, kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3B5x07o3CSY7"
   },
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "  \n",
    "        # Add network layers here\n",
    "        self.layer1 = nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "           \n",
    "\n",
    "        #Second cnn sequence\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 24, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3))\n",
    "\n",
    "        #third cnn sequence\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(24, 32, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32,40 , kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(40, 48, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.3))\n",
    "\n",
    "\n",
    "        # Fully connected layers\n",
    "\n",
    "        self.fc1 = nn.Linear(1200, 256)         \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "         \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(torch.nn.functional.relu(self.layer1(x)))      \n",
    "        x = torch.nn.functional.dropout(x, p=0.3)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2PG5UzhZJ4b"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsMc_DunaqwM"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzlrakR7ae5w"
   },
   "outputs": [],
   "source": [
    "model_gpu = ConvNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model_gpu.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERS VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p1HlGUFG6Yg"
   },
   "outputs": [],
   "source": [
    "def normalise_filters(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "def filter_visualization():\n",
    "    filters = model_gpu.layer1.weight.data\n",
    "    filters = filters.to(\"cpu\")\n",
    "    filterNP = filters.numpy()\n",
    "\n",
    "    filterNumber = 4\n",
    "    picID = 1\n",
    "    for k in range(0, 16):\n",
    "      graph = plt.subplot(filterNumber, 4, k+1)\n",
    "      graph.set_xticks([])\n",
    "      graph.set_yticks([])\n",
    "      #normalise filters\n",
    "      plt.imshow(normalise_filters(np.clip(filters[k],0,1)[:,:,0]), cmap='gray') #Red\n",
    "    plt.show()\n",
    "    print(\"Red\") \n",
    "\n",
    "    for k in range(0, 16):\n",
    "      graph = plt.subplot(filterNumber, 4, k+1)\n",
    "      graph.set_xticks([])\n",
    "      graph.set_yticks([])\n",
    "      plt.imshow(normalise_filters(np.clip(filters[k],0,1)[:,:,1]), cmap='gray') #Green\n",
    "    plt.show()\n",
    "    print(\"Green\")\n",
    "\n",
    "    for k in range(0, 16):\n",
    "      graph = plt.subplot(filterNumber, 4, k+1)\n",
    "      graph.set_xticks([])\n",
    "      graph.set_yticks([])\n",
    "      plt.imshow(normalise_filters(np.clip(filters[k],0,1)[:,:,2]), cmap='gray') #Blue\n",
    "    plt.show()\n",
    "    print(\"Blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function that enables to visualise filters before training, during and after training using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emEeFFATxrWm"
   },
   "outputs": [],
   "source": [
    "def train_model_epochs(num_epochs):\n",
    "    \n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        if(epoch == 0):\n",
    "            print(\"Filter Visualization before training\")\n",
    "            filter_visualization()\n",
    "\n",
    "        running_loss = 0.0  #calculates overal batch loss for each epoch\n",
    "        batch_count1 = 0    # how many time it runs over train_loader\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            images, labels = data\n",
    "\n",
    "            # Explicitly specifies that data is to be copied onto the device!\n",
    "            images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
    "            labels = labels.to(device)  # <----------- variables still exist on CPU\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_gpu(images) #produces the model\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_count1 +=1\n",
    "            \n",
    "        print(\"Training loss for Epoch \", epoch+1, \", is \", running_loss/batch_count1)\n",
    "        train_losses.append(running_loss/batch_count1)\n",
    "\n",
    "\n",
    "        running_val_loss = 0.0\n",
    "        batch_count2 = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for b, vdata in enumerate(valid_loader, 0):\n",
    "          \n",
    "            images, labels = vdata\n",
    "            images = images.to(device)  # \n",
    "            labels = labels.to(device)  # \n",
    "\n",
    "            outputs = model_gpu(images)\n",
    "\n",
    "            # Compute the loss based on the true labels\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "            batch_count2 +=1\n",
    "\n",
    "        print(\"Validation loss for Epoch \", epoch+1, \", is \", running_val_loss/batch_count2)\n",
    "        valid_losses.append(running_val_loss/batch_count2)\n",
    "\n",
    "\n",
    "        if((epoch+1)==(num_epochs//2)):\n",
    "            print(\"Filter Visualization during training\")\n",
    "            filter_visualization()\n",
    "\n",
    "        if(epoch==(num_epochs-1)):\n",
    "            print(\"Filter Visualization after training\")\n",
    "            filter_visualization()\n",
    "\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(valid_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylim(0, 4)\n",
    "    plt.show()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJ1KDLHKzpg6"
   },
   "outputs": [],
   "source": [
    "train_model_epochs(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jsQoJxKCbbtc",
    "outputId": "432fa71c-8c9d-4211-b5db-ce8ecee800de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labs = []\n",
    "\n",
    "    # Iterate over the test set\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        all_labs.extend(labels)\n",
    "\n",
    "        images = images.to(device)  \n",
    "        labels = labels.to(device)  \n",
    "        \n",
    "        outputs = model_gpu(images)\n",
    "                \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().detach().clone().numpy())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "cm = confusion_matrix(all_labs, all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVyYM3nlIciq"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Specify the tick marks and axis text\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # The data formatting\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    # Print the text of the matrix, adjusting text colour for display\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "qJ_dovfGF405",
    "outputId": "b1108ec0-9d24-40fd-caa6-94d286973eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEYCAYAAACgIGhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3gUxRvHP5OETqgpQAJCKAFCCynU\n0LsggkBooRelKSqKioigCDakihQFQQFBpYQSCL2EXpTeS0IooZMAafP74y4hlCO5292Q/JzP8+RJ\nbm73O292996bnZ35jpBSolAoFM/D7mUHoFAoMi4qQSgUCouoBKFQKCyiEoRCobCIShAKhcIiKkEo\nFAqLqATxf4wQIocQYoUQ4o4QYrEGnS5CiLV6xvayEEIECCFOvOw4MgtCjYN4+QghOgPvAmWBe8BB\n4Esp5TaNukHAYKCmlDJec6AZHCGEBEpLKU+/7Fj+X1AtiJeMEOJd4AdgLOAKFAOmAa11kH8FOPlf\nSA5pQQjh8LJjyHRIKdXPS/oB8gL3gfYv2CYbpgRy2fzzA5DN/F49IBx4D7gGRAI9ze99DsQCceY6\negOjgPkptIsDEnAwv+4BnMXUijkHdElRvi3FfjWBPcAd8++aKd7bBIwBtpt11gJOFv63pPg/SBH/\n60AL4CRwE/g4xfb+QBhw27ztFCCr+b0t5v8l2vz/BqbQ/xC4AsxLKjPvU9JcR1Xz6yLAdaDey742\nMsrPSw/gv/wDNAPikz6gFrYZDewEXABnYAcwxvxePfP+o4Es5g9WDJDf/P7TCcFiggByAXcBT/N7\nhQEv89/JCQIoANwCgsz7dTK/Lmh+fxNwBigD5DC/Hmfhf0uKf6Q5/r7mD+jvgCPgBTwASpi39wGq\nm+stDhwD3kmhJ4FSz9EfjynR5kiZIMzb9AWOAjmBEODbl31dZKQfdYvxcikIRMkX3wJ0AUZLKa9J\nKa9jahkEpXg/zvx+nJRyFaZvT08b40kEKgghckgpI6WUR56zzavAKSnlPCllvJRyAXAcaJVim1+k\nlCellA+AP4AqL6gzDlN/SxywEHACJkop75nrPwpUBpBS7pNS7jTXex74Caibhv/pMynlI3M8TyCl\nnAmcBnZhSoqfpKL3n0IliJfLDcAplXvjIsCFFK8vmMuSNZ5KMDFAbmsDkVJGY2qWvwlECiFWCiHK\npiGepJjcUry+YkU8N6SUCea/kz7AV1O8/yBpfyFEGSFEsBDiihDiLqZ+G6cXaANcl1I+TGWbmUAF\nYLKU8lEq2/6nUAni5RIGPMJ0322Jy5g6G5MoZi6zhWhMTekkCqV8U0oZIqVsjOmb9DimD05q8STF\nFGFjTNbwI6a4Sksp8wAfAyKVfV74mE4IkRtTv85sYJQQooAegf6/oBLES0RKeQfT/fdUIcTrQoic\nQogsQojmQoivzZstAEYIIZyFEE7m7efbWOVBoI4QopgQIi/wUdIbQghXIURrIUQuTEnrPqbm+dOs\nAsoIIToLIRyEEIFAeSDYxpiswRFTP8l9c+vmrafevwp4WKk5EdgrpewDrASma47y/wiVIF4yUsrv\nMI2BGIGpg+4SMAhYat7kC2Av8A/wL7DfXGZLXeuARWatfTz5obYzx3EZU89+XZ79ACKlvAG0xPTk\n5AamJxAtpZRRtsRkJe8DnTE9HZmJ6X9JyShgrhDithCiQ2piQojWmDqKk/7Pd4GqQoguukWcyVED\npRQKhUVUC0KhUFhEJQiFQmERlSAUCoVFVIJQKBQWyVCTV+yy55H2js6663oVzae7ptHEJxjXeZzV\nIXN9LyQa2JGe8LwHuTqQxT614RkZi4sXzhMVFfVM0BkqQdg7OuPU9uvUN7SSDd/rMTHy+SQkGnPx\nRt2LNUQXoLhzztQ3sgGjjsWjOIM+xcDdh8ZMdHXJk80QXQA7A3JPrep+z69L/6oUCsX/CypBKBQK\ni2TIBPF9Nx/+/eZVNo5slFyWL2cWFr5dm+2jm7Lw7drkzZkFgLw5s/Dzm9VZ/2kjVg2vj2eRPDbV\neerkCerW8En+eaVwAaZPnajL/zNj2mTqVKtCgH9lfpo6yWadyIhwerRrTst6PrSq78u8WVMBmPT1\naF5vVI02jWvQp9NrXLsSqSne/n178YqbK75VKmrSeZqHDx9Sr3Z1avh54+ddkS9Hj9JN+8cpP1DL\nrzK1/avQt2dXHj5MbX6WZT4Y0h+/csVoFuCTXDa4T1derVeNV+tVI6CqJ6/Wq6Yp3vBLl2jepAE+\nlb3wrVKBqZP1udb0PncZMkH8EXaBzpO2P1E2qJkn245fo9bIELYdv8agZqYZzUOal+Vw+B0ajgll\nyC97GRNY2aY6S5fxZHPYPjaH7WPDtt3kzJGTV1u9aA5V2jh29DDz585mzcYdbNyxj7Uhqzh7xjZH\nNAcHBz747CuCN+1j4YqN/D5nJqdPHqPXW++wNHQXf68Lo26jZkyb8JWmmIO69WBp8GpNGs8jW7Zs\nBK8JJWzPAXbs3k/ouhB279qpWTfycgQzp08ldMtOtu0+SGJCAn8veXoUdtpp1zGIXxYue6Js8qz5\nrNy0i5WbdtGs5es0bamtX8vBwYGvxn/LvkNH2Lg1jJnTp3Hs2FFNmqD/ucuQCWLnqShuxTzZSde0\nchH+CLsIwB9hF2lW2TTjuUxhR7YfvwbA6av3KFowJ06O2jqItmzaQHEPD4oWe3rSovWcOnGcqr7+\n5MyZEwcHB2rWCmDliqWp7/gcnF0LUb6iyVohV25HPEp7cu1KJLkdH7eaHsTEIIS2XqzaAXUokF//\nSY1CCHLnNs38jouLIy4uTnOsScTHx/PwwQPi4+OJiYmhUOEiqe9kAf+atcln4f+XUrJq2Z+0apPq\nVI8XUqhwYap4VwXA0dERz7LliIzQPiFW73OXIRPE83DOk41rd03Nxmt3H+Js7iU+Gn6HFt4mK4Iq\nxfPjXiAnRfLn0FTXX0sW0bZdoLaAzZQt78XOHdu4eeMGMTExhK5dw+XwcM26EZcucOzwISp5+wLw\nw7hRNPD1JPjvRQweNkKzvlEkJCRQ078qHkULUb9hI/z8tTXVAQoXcWPgkKFUKe+BV6mi5Mmbh/oN\nG+sQ7bPsCdtOQWdXSpQspZvmhfPnOXToAL46HAu9MTRBCCGaCSFOCCFOCyGG66md9Gh88poT5MmZ\nhXUjGtK7fkkOX7qt6XFbbGwsa1YG07pNO13iLONZjsFDh9GhTQs6tm1JhUqVsbe316QZHX2ft/t2\n4aPPxye3Ht4ZPooNe0/Qsk0gv/3ykx6hG4K9vT07du/n+JmL7Nuzh6NHDmvWvH3rFqtXrmDfv6c4\nfOoiMdEx/LHwNx2ifZblf//Ba23b66Z3//59unRsx/hvJ5Anj239Z0ZiWIIQQtgDU4HmmPwCOgkh\nytuqd/3uI1zyZAfAJU92ou6ZjH/uP4xn6Nx9NP5iPYN/2UvB3Nm4EBVtc9yha9dQqYo3Lq6uNms8\nTZduPQndsovlazaQL18+PEqVtlkrLi6Od/p2oWWbQBq3ePY+uGXbQNatWvacPTMW+fLlo07deqxb\nG6JZa/Om9bzySnGcnJ3JkiULLV97nT27wnSI8kni4+MJWbmMV1/X58sjLi6OLoHtCOzYmdavt9VF\nU2+MbEH4A6ellGellLGY/AZt7tlZ+08kHWoUA6BDjWKEHDKZKuXJkSV51FqX2sXZeSqK+xoGv/y1\neBFt2+tze5HE9eumPpLwSxdZuXwpb7TvaJOOlJJP3xuARylPevQfnFx+/uzjTs8NIcF4lCyjLWCD\nuH79Ordv3wbgwYMHbFgfShlPW+0zH+PuXpS9e3YTExODlJItmzZQxvN5bnna2L55AyVLlaFwEXfN\nWlJKBvTvg2fZsgx+510dojMGI0dSumEyP0kiHEjTTda03v7U9HSiQO5s7BvXnG9XHGPKmhP81K8a\nnWqVIPxmDP1nmHq/Sxd2ZGIPX6SEk5F3effXfTYHHB0dzaaNoXw/aZrNGs+jV9dAbt28gUOWLIz7\nbhJ589k29Hv/njCW/7mAMuW8aNO4BmC6tfhr4VzOnTmFnZ0dRdyK8dk4bY/MunftzJYtm7gRFUWp\nEkUZMXIUPXr21qQJcPVKJP379CQhIYHExETavtGe5i1aatb18atGq9fb0qC2Pw4ODlSsXJluPfva\nrDekXzd2bd/KrZtR1KxUkrc/+JTArj0I/nsxrdpq65xMImzHdhb8Ng+vChWp4ecNwKjRX9K0eQtN\nunqfO8MMY4QQ7YBmZiuvpFWeqkkpBz21XT+gH4Bdbicfl876O34dUUOtn0ANtX6MGmptolZ1P/bv\n2/uMspG3GBFA0RSv3XmOsamUcoaU0ldK6WuXPeN10igU/2WMTBB7gNJCiBJCiKxAR2C5gfUpFAqd\nMawPQkoZL4QYhGm1InvgZwsLsSgUigyKodO9zSs9rTKyDoVCYRyZZiSlQqFIf1SCUCgUFlEJQqFQ\nWEQlCIVCYZEM5UlZsVh+tk/Rf0x6Af/BqW9kI1G7JhuiWzy7cacm5lFC6hvZQC6DYo42KF6A/Lmy\nGKIbZ5QbLo8nKqaHpmpBKBQKi6gEoVAoLKIShEKhsIhKEAqFwiIqQSgUCotkugSh1dZ7+mdduLD+\nK/Yu/ji5bOSAV9m96CN2LhzOimkDKeycF4A8ubOz5If+7Fo0nH1LPiHotepW12eUvTkYZ0+vp4X8\n06wNWUMlL0+8ypbim6/H2azzzsC+eJV0o271Ksllt27epEPr5tTwLk+H1s25feuW5ngrlS1JTb8q\nBFTzoX4tfT0jjdK+c/s23bt0oJq3F9WqVmC3BnetTJcgtNp6z1uxk9YDpz5RNmHuevwDv6J6x3Gs\n3nqYj/o1B6B/hzocP3uFaoHjaNp3IuPebUMWB+v8JI2yNwdj7On1tpBPSUJCAu8MGciyFas58M9R\nFi9cwLGjth2LwM7dWPBn8BNlkyd8TUDd+oQdOEpA3fpMnqDPMo4rVoeyddc+Nm7fpYue0dofDRtK\nw8ZN2XXgCFt37sfTs5zNWpkuQWi19d6+/ww378Q8UXYv+vE3ZM4c2Ugy0ZFA7lwm449cObJx604M\n8VY+3zbK3hyMs6fX00I+JXt276ZkyVKU8PAga9astA/sSPAK2/wza9QKIF/+/E+UhaxaQYfOQQB0\n6BzEmpX/PXeBu3fusGP7VoK69wIga9asNjuYQSZMEEYxamArTq0eQ8fmvoz5cSUA0xdupmyJQpxd\n+yV7F3/M+98sQYsDV0a2N0/CSAv5y5cjcHd/7CHk5uZOhE7JEkzen66FCgPg4loo2QtUC0II2rZq\nTr2a/syZPVOzntHaF86fw8nJiUH9e1O3hi9DBvQjOtp2E2cjXa1/FkJcE0Jo9zVPB0ZNXUHp5p+y\ncPVe3gysA0DjmuX450Q4Hk0+oVrHr5gwvD2OubLbpJ/R7c2TSE8LeSMRQiDQ7s22OnQzm8P2sHhp\nMLNm/Mj2bVt0iM447fiEeA4dPEDPvv3ZHLaXnDlz8cN3423WM7IFMQdoZqC+ISxatYfXG5o6voJe\nq86yDYcAOHspivMRN/Asbr0dfmawN0/CSAv5IkXcCA9/7GMcERGOm5ubLtoAzs4uXDWvS3r1SiRO\nzs6aNYuY43N2caFlq9bs37tHs6aR2kWKuFPEzR1fP1MrtXWbtvxz8IDNeoYlCCnlFuCmUfp6UrLY\n4wupZb1KnDx/FYBLV25Rz99ky+5SwJEyxV05FxFllXZmsTdPwkgLeV8/P06fPsX5c+eIjY1l8aKF\nvNryNV20AZo0b8Ufv88D4I/f59G0RStNetHR0dy7dy/57w3r11GuvJfmOI3Udi1UCDd3d06dPAHA\n5k0b8CxreyflS5+sldLVumixYqlur9XWe+5XPQjwKY1TvtycXjOGMdNX0ay2F6VfcSExUXIx8iZD\nvlwIwLiZa5jxeVf2/PExQsAnE5dx47Z193NG2ZuDMfb0elvIp8TBwYEJE6fQ6tWmJCQk0L1HL8p7\n2faheLNXV3Zs28LNG1F4lyvBsI9GMvjdYfTr3pnf583BvWgxZsz5XVO8169dpWtH0yI5CfHxvNGh\nI42a6NMoNlJ7/LcT6d+rG7GxsRQvUYIp02fbrGWY7T2AEKI4ECylrJCW7av6+MrtO/VrwiWRGWdz\nGmFtnkRmm815JybOEF2AbFkyXz+9ER/ZBrWrcWB/+treKxSKTI5KEAqFwiJGPuZcAIQBnkKIcCGE\n9rXbFApFumLkuhidjNJWKBTpg7rFUCgUFlEJQqFQWEQlCIVCYRGVIBQKhUVe+kjKlEgJD+P0twuP\n2PaD7ppJOLWdZohu1F8DDNEFiI41ZqCUnUGju4y1kDdmoKC9gSPdHHPob9VvKVzVglAoFBZRCUKh\nUFhEJQiFQmERlSAUCoVFMl2C0NOxNyWnTp6gbg2f5J9XChdg+tS0O1BPf7sBF+b3ZO/UjsllY3vW\n5OCPndk9OZBFnzQnb66sAPiWcWHnpEB2Tgpk1+RAXqtRwup49XbLfn9wP6p6FqVxrarJZRPGj8Hf\ny4Pmdf1pXtefDevWaKoD9Dt/7w3qR5UyRWlYs+oz7/005QeKFsjOzRvWeXckMXRgPyqUcqdeDe/k\nshVL/6Ru9SoUyZ+dgwf22aT7NDOmTaZOtSoE+Ffmp6mTdNEE/ZzDIRMmCD0de1NSuownm8P2sTls\nHxu27SZnjpy82ur1NO8/L/QYrT9b8UTZ+oOX8Bm4AP/BizgVcZth7X0AOHLhJrXe+YPqQxbReuQK\nJg+sZ3Wvt95u2e07BTH3j2dNXnu/NZjVm3ezevNuGjTW7leg1/lr3zmIeYufjfdy+CW2bAzFLYX3\npbV06BzE70uePJee5coze94iqtcMsFk3JceOHmb+3Nms2biDjTv2sTZkFWfPnNasq6dzOGSyBKG3\nY68ltmzaQHEPD4oWeyXN+2w/EsnNe4+eKFt/4BIJiabHaLtPXMHNKTcADx7FJ5dny2pv0/x+vd2y\nq9V81iVab/Q8f9UtxPv5Jx/wyedjEcL2x4w1agWQ/yntMp7lKFXa02bNpzl14jhVff3JmTMnDg4O\n1KwVwMoVSzXr6ukcDpksQejt2GuJv5Ysom27QF01uzUuR8jeC8mv/cq4sm9qJ/ZO6cSQaZuSE4Yt\nGOmW/eusH2ka4Mv7g/tx57a2hWiMPn8hq1ZQqHARyleopJumUZQt78XOHdu4eeMGMTExhK5dw+Xw\ncM26ejuHGzndu6gQYqMQ4qgQ4ogQ4m2tmno79j6P2NhY1qwMpnWbdrppftDBh4QEycJNJ5PL9py8\nis/ABdQeuphh7X3IlsW6BXmSMNItu2vPfmzZd4zVm3fj4lqIMZ9+qEnPyPP3ICaGKd9/zXsfj9RF\nz2jKeJZj8NBhdGjTgo5tW1KhUmXs7W27BozEyBZEPPCelLI8UB0YKIQor0VQb8fe5xG6dg2Vqnjj\n4mq9e/Xz6NqwLC38i9Pj23XPff9E+C3uP4jD6xXrF8Ax2i3b2cUVe3t77Ozs6NStF4f279WkZ+T5\nO3/+LJcunqdpgB81Kpch8nIEzetV59rVK7roG0GXbj0J3bKL5Ws2kC9fPjxKldasqbdzuJGu1pFS\nyv3mv+8BxwBNHud6O/Y+j78WL6Jte31uLxpXLca7b3jTbvRKHjyKTy5/xdUxuVOymLMjnu75uXDt\nnlXa6eGWnWQhDxCycjme5bS5Lht5/sqVr8DBk5cIO3SSsEMnKVzEjdWbduLiWkgXfSNIWtgn/NJF\nVi5fyhvtO6ayR+ro7RyeLnMxzOa13sAzCxCmdLV2L5q6q7Wejr1PEx0dzaaNoXw/yfr5FXOHNSag\nohtOebJzek53xvy223zrYEfwF60BU0flkKmbqVm+MO+38yEuIZHERMnbP27mxl3rFsjV2y17cN8g\nwrZv5daNKKpVKMnQ4SPYuW0LRw//gxAC92KvMPa7KTZpp0Sv8zewTxA7t2/l5o0o/LxK8t7wEXQM\n6qk5PoC3egclO2ZXLe/B+8M/JV/+Aoz4cCg3oq4T1OF1vCpWYuFfKzXV06trILdu3sAhSxbGfTdJ\nlw53PZ3DwWBXawAhRG5gM/CllPKvF23rXdVXbtim/wKpRv6PboE/GaJr5GStG/djDdF1NMjVOjpF\n60tvHAyaVJXZJmvVqubLvn3p7GothMgC/An8llpyUCgUGQ8jn2IIYDZwTEr5vVH1KBQK4zCyBVEL\nCAIaCCEOmn+0LyelUCjSDSNdrbeBDssrKxSKl0amGkmpUCjSF5UgFAqFRVSCUCgUFlEJQqFQWCRD\nuVrffxTPznM3dNetVCSv7ppJXF3yliG6b8zabYguwJLefoboapiQ+kKM7OnWMov2RWTPatzEKyMG\n/llSVC0IhUJhEZUgFAqFRVSCUCgUFlEJQqFQWCTTJIiEhAQGtWvIZwO6ALDi99n0bl6NFhVcuXPL\nto7N9wb1o/JTzsjffDmKRrV9aVLHn85tX+VK5GXd4q9d3YcObVtp0mlTqRA/dazI9MCKDG9ckiz2\nj7vw3qr9Cn/39dUaKg8fPqRe7erU8PPGz7siX44epVkzJXocCyPPXXpdF5XKlqSmXxUCqvlQv5Y+\ndoH9+/biFTdXfKtU1EUv0ySIZfNnUtTjseNOeW9/xs5ajEsR292L23cOYv5TzshvDn6X0G17Wbtl\nNw2btuCHb8barJ+SH6dMwtOzrCaNgrmy0LqSK4MXH+bNRf9iJwT1ShUEoLRzLnJn0+ehVLZs2Qhe\nE0rYngPs2L2f0HUh7N61Uxdt0OdYGHnu0vO6WLE6lK279rFxuz42B0HderA0eLUuWpBJEkTUlcvs\n2bKOpm90SS4rWa4irm6pG8y8iOc5Izum8HV8EBOtyR05iYjwcELWrKJbz96ateztBFkd7LATkM3B\njhsxcdgJ6FOzGLPDLmrWBxBCkDu3yYE7Li6OuLg4XY4D6HcsjDx36XVdGEHtgDoUyG+9faElMtQ4\nCEv8NP5Ter07kgfR99OlvvFfjGTJwt/IkycvfywP0aw3fNhQRn85jvv3rbOVe5ob0XEsORjJvG7e\nPIpPZP+lO+y/dIfWlVzZee4WN2PiNMeaREJCAgE1/Dh75jR93xyAn06O2XodC0vofe6M1BZC0LZV\nc4QQ9Ojdlx69++oQpb4Y6QeRXQixWwhxyOxq/bktOrs2rSVfASdKe1XWO0SLfDhiNHsOn6FN+478\nMvNHTVprVgXj7OKCd1UfzXHlzmZPjeL56THvIF3mHiC7gx0NPZ2oU7Igy/7V15zV3t6eHbv3c/zM\nRfbt2cPRI4c1a+p5LCyh57kzWnt16GY2h+1h8dJgZs34ke3btugQpb4YeYvxCGggpawMVAGaCSGq\nWyty9MBudm4KoUcTX8YP688/u7fzzYfG2bGlpE37jqzWuJjJzrAdrA5eQUVPD3p168yWTRvp2zPI\nJi1v97xcvfeIOw9NC+9sP3eLID83CufNxi9dqjC3axWyOdjxcxf9kmm+fPmoU7ce69Zq/8bU81ik\nhh7nzmjtIma3aWcXF1q2as3+vXs0a+qNka7WUkqZdE+Qxfxj9RjRnkNHMG/9Qeas3cuH3/xEJf9a\nDBtvvalsWkm5/FnIqmBKalxNadSYsRw7c5F/T5zl519/p069+sz8ZZ5NWtfuPaKsa26yOZhOWxW3\nPPx16Aqd5xyg+/yDdJ9/kEfxifT67ZCmmK9fv87t27cBePDgARvWh1LGU/uqUnoei+eh97kzUjs6\nOpp79+4l/71h/TrKldfmGm4EhvZBCCHsgX1AKWCqlPKFrtYuhd3TrL1s/kyW/DKVW1HXGNi2Pr4B\nDXln9ASr4hvYx+TkfPNGFL5mZ+QN60I4e/okws4O96LF+Oq7yVZpGsmJa9FsPXOTKe0rkJAoORMV\nw+oj13Sv5+qVSPr36UlCQgKJiYm0faM9zVu01L0eLRh57tLjurh+7SpdO5oWZ0qIj+eNDh1p1ET7\n2qfdu3Zmy5ZN3IiKolSJoowYOYoeGjqEDXe1BhBC5AP+BgZLKS3ezJb2qiIn/bFW9/qNnKxlhMMw\nQIefjWtuZrbJWvce6Nf5ml7kMsjhG0huQepJrep+7E9vV+skpJS3gY2A9hSpUCjSDSOfYjibWw4I\nIXIAjYHjRtWnUCj0x8g+iMLAXHM/hB3wh5Qy2MD6FAqFzhjpav0PpuX2FApFJiVTDLVWKBQvB5Ug\nFAqFRVSCUCgUFlEJQqFQWEQlCIVCYRGLTzGEEHksvQcgpbyrdzB5sjtQ39NFb1kexCborplESkcn\nPVnaT5/p1c8jf6sfDNE9/bsxSwDcexhviC5Akfw5DNE1yk4/vXnRY84jmCZXpfwEJL2WgDa3FoVC\nkeGxmCCklLZ7uSkUiv8L0tQHIYToKIT42Py3uxDCOMcPhUKRYUg1QQghpgD1gSRnjxhgupFBKRSK\njEFaWhA1pZT9gYcAUsqbQFZDo3oBa0PWUMnLE6+ypfjm63G6at+5fZvuXTpQzduLalUrsHtXmGZN\nvW3IU6LlWEwf2pgLC/qx98euyWVje9fm4Ixu7J7WhUWftiRvrmwAFHPJw82lg9g5pQs7p3Rh0qAG\naa7HKAv5yIhwurdrTsu6PrSs58uvs6aatEd/QosAb1o3rMagXh25e+e21dpPo9eSBU+TGa63tCSI\nOCGEHWY3KCFEQSBRl9qtJCEhgXeGDGTZitUc+Ocoixcu4NjRo7rpfzRsKA0bN2XXgSNs3bkfT89y\nmjX1tiFPQuuxmLfuKK1H/P1E2foDF/F5cx7+A37jVMRthgU+9o04G3mb6oN+o/qg3xgyZUOa6zHK\nQt7ewYEPRn5F8OZ9LAreyO9zZnL65DFq1mnA8o17WLZ+F8U9SjNj8ndWaz+NHjb9zyMzXG9pSRBT\ngT8BZ7Px7DZgvG4RWMGe3bspWbIUJTw8yJo1K+0DOxK8Ypku2nfv3GHH9q0Ede8FQNasWcmbL59m\nXb1tyJPQeiy2H47g5r1HT5St338x+fHc7uORuDnl1hynURbyLq6F8KpUBYBcuR0pWcqTq5GR1KrX\nEAcHU997ZR8/rkZGaIhe3yULUpJZrrdUE4SU8ldgBPAtcBNoL6VcqFsEVnD5cgTu7o8frri5uRMR\noe0CSOLC+XM4OTkxqH9v6qqSiSwAACAASURBVNbwZciAfkRHR+uibQRGHguAbk28CNlzPvl18UJ5\nCZvSmbVft6OWVxHN+uO/GIlfhZL8vXgh7380UpNWxKULHDt8iMpVn1xV7K8F8who0ESTdpJNv52d\nvmMKM8v1ltb/2h6IA2Kt2Acw+VIKIQ4IITK0F0R8QjyHDh6gZ9/+bA7bS86cufjhu5fSUHrpfNDR\nj4SERBZuNPn7XLkVTZlus6kx6Hc+nLGFOR82xzGntm4ovSzko6PvM6RPF4aPHk9ux8ctk+kTv8be\nwZ5WbQNt1jbSpj+zXG9peYrxCbAAKAK4A78LIT6yoo63gWO2hfckRYq4ER5+Kfl1REQ4bmbrcO3a\n7hRxc8fXzzSCsXWbtvxz8IAu2kZg1LHo2qg8Lfw96PH1muSy2LgEbt57CMCB09c4G3mH0m7am8Og\nzUI+Li6Ot/t0oVXbQJq0aJ1c/vei+WwKXcM3U37WtAKWkTb9meV6S0troBvgJ6UcIaX8BPAHeqRF\nXAjhDrwKzLI5whT4+vlx+vQpzp87R2xsLIsXLeTVlq/pIY1roUK4ubtz6uQJADZv2oBnWe2dRkZh\nxLFo7PMK77b3od3ny3nw6PHwZqe8ObCzM33QihfKQ6ki+TgXecfmevSwkJdSMuK9AXiU9qRH/8HJ\n5Vs3rmP2tAlMm7OIHDlz2hwjGGvTn1mut7Q4SkU+tZ2DuSwt/AB8ADha2iCl7X3RYi8eve3g4MCE\niVNo9WpTEhIS6N6jF+W99FtLYPy3E+nfqxuxsbEUL1GCKdNna9bU24Y8Ca3HYu6HzQmo5I5Tnuyc\nntebMfN2MizQj2xZ7An+si1g6qgcMmUDtSu48WlQDeLiE0mUksFT1nPr/qNUajBhlIX8/t1hLF+y\ngDLlvGjTqAYA73w0irGfDiP20SN6B5qSZWUfP0aNn2S1fnqQGa43i7b3QogJmB5tFgf8gBDz6ybA\nHilluxcKC9ESaCGlHCCEqAe8L6V84eIKPj6+cvuuvdb+D6li5GSt7FmMmRBr5OKwarLWYzLjZC0j\nrjlLtvcvakEkrV9xBFiZojyt68DXAl4TQrQAsgN5hBDzpZRdU9lPoVBkEF40WUtTe0dK+RHwEUCK\nFoRKDgpFJiLVPgghREngS6A8ppYAAFLKMgbGpVAoMgBpuZmZA/yCyQeiOfAHsMiaSqSUm1Lrf1Ao\nFBmPtCSInFLKEAAp5Rkp5QhMiUKhUPyfk5bHnI/Mk7XOCCHeBCJ4wWNLhULx/0NaEsRQIBcwBFNf\nRF6gl5FBKRSKjEGqCUJKucv85z0em8YoFIr/AC9ytf4bswfE85BSttU7GIkxA0yMHCiV1cGYgVJ2\nlg+9ZvbM7GOI7mtTdhiiO7ljFUN0AfLlzGKIrr2dcQPdMGhw3vN4UQtiSrpFoVAoMiQvGii1Pj0D\nUSgUGQ+1spZCobCIShAKhcIiaU4QQohsRgaSFsIvXaJ5kwb4VPbCt0oFpk6eqEnv3UH9qFTanQY1\nvJPLxnw6nDr+FWlUy4feXdtzR6Mrst4xp0QvB+Mrl8Pp1aEFrRv48npDP+bPngbAtO/H0tC3DO2a\n1qRd05ps2RBik34nf3cW9ffjjzf96eTv/sR7XasXZd+n9cmXw7rOwkePHtLnjUZ0bxVAlxY1mDXx\nKwC++HAg7RpUoftrdej+Wh1OHv3X6niHDuxHhVLu1EtxXaxY+id1q1ehSP7sHDywz2rN5zFj2mTq\nVKtCgH9lfpqqz5T0dHe1FkL4CyH+BU6ZX1cWQlg/gV8HHBwc+Gr8t+w7dISNW8OYOX0ax47Z7mrd\noVMQvy1Z8URZnfoN2bDjAKHb9+FRsjRTvv86Q8WcEr0cjO3tHXj/07Es27CX35ZtYOHcGZw5abKb\nC+ozkCUhO1gSsoM6DZparV3SORevexem++x9dPppDwGlC+JunmLtmicb1T0KEHn7odW6WbNmY9Kv\nS5m7Yitzl21h19b1HD64B4CBH3zO3OVbmLt8C2XKW/9B6dA5iN+fui48y5Vn9rxFVK8ZYLXe8zh2\n9DDz585mzcYdbNyxj7Uhq54w0rGVl+FqPQloCdwAkFIewrSQTrpTqHBhqnib1ldwdHTEs2w5IjUY\ntVav9azjct0GjZNdkav6VSPysjYjWL1jToleDsbOroUoX/GxQ3SJUp5cvWL9WhXPo4RTTg5H3OVh\nfCIJUrL/4m0alHUG4N0mpZi4/jTShke6Qghy5jK5bsfHxxEfH6+bh0aNWgHkf+q6KONZjlI2OF9Z\n4tSJ41T19Sdnzpw4ODhQs1YAK2203ktJurtaA3ZSygtPlRk3sCCNXDh/nkOHDuDrb9wq2Avnz6F+\nI+u/NS2RHjFrJeLSBY4f+YdK3iaH6AVzZ9C2cXU+fe8t7ty+ZbXe6evReBfLR94cDmR3sKNWqYK4\n5slG3TJOXL/7iFNXbXdyTkhIoPtrdWhZwxO/WvXwqmyK+acJX9KtVW0mjv2Y2Ni0OV+lN2XLe7Fz\nxzZu3rhBTEwMoWvXcDk8/GWH9QxpSRCXhBD+gDQ7VL8DnEyLuBDivBDiXyHEQSGEblZR9+/fp0vH\ndoz/dgJ5UqyxoCcTvx2Hg4MDbTt00kUvPWLWSkz0fYb278qHo8aR2zEPHYL6sGrbPywJ2YGzSyG+\nHfOx1Zrno2KYu+MiU7tUYXLnypy8cp+sDnb0qv0K0zef0xSvvb09c5dv4e8thzn6z37OnjzKm+99\nyoI1u5j153ru3r7N/Bn69fnoSRnPcgweOowObVrQsW1LKlSqjL29/csO6xnSkiDeAt4FigFXgerm\nsrRSX0pZRUrpm/qmqRMXF0eXwHYEduxM69d1H8wJwKLffyV07SqmzJirS7M1PWLWSlxcHEP7deXV\n1zvQqLnJIdrJ2QV7e3vs7Ox4o3MPDh+0rXNu2cFIus7aS99fD3D3YTxnr0dTJF92FvTzY8Xg6rjk\nycZvfX0pmMs2K33HPHmpWq02O7eux8mlEEIIsmbNxqtvdObYP/tt0kwPunTrSeiWXSxfs4F8+fLh\nUar0yw7pGdIyF+Ma0DEdYkkVKSUD+vfBs2xZBr/zriF1bAwN4cdJ3/FncKhmV2RIn5i1IqXks2ED\n8SjtSfd+jx2ir1+9grNrIQDWr1lBKc/yNunnz5mFWzFxFMqTjQZlnej+834W7H7cnF4xuDpBs/Zx\n+0FcmjVv3YzCwSELjnny8ujhA/Zs30TXfm8Tde0KTi6FkFKyJXQlHqUznlN0EtevX8PZ2YXwSxdZ\nuXwpq9dve9khPUNaHKVm8pw5GVLKfmnQl8BaIYQEfpJSzniOfppdrcN2bGfBb/PwqlCRGn6mR1Cj\nRn9J0+Yt0hDKswzoHUTY9i3cvBGFj5cH7w//lCkTvubRo1g6tjFpVvX1Z/yEqTbpGxFzSvRyMD6w\nJ4wVfy6gdFkv2jWtCcCQDz9j9bIlHD/yD0II3NyLMXKcbY/ivmlfgbw5shCfKBm3+hT3H2k3ob1x\n7SpffDiAxMQEEhMTadD8dWrVb8rgbq25fTMKKSWly1Vk2OfWr835Vu8gdmwzXRdVy5uui3z5CzDi\nw6HciLpOUIfX8apYiYV/rUxd7AX06hrIrZs3cMiShXHfTdJl6b10c7VO3kCIlEsTZQfaAJeklIMt\n7JJyXzcpZYQQwgVYBwyWUm6xtH1VH1+5NWxP2iK3gjsxaf9mspa8Bk32MXKuzxkNHYMvovsv+p87\nMHaylodLLkN0jZyslTt7WlwarMMWV2sApJRP2MsJIeZhWsA3VaSUEebf18yzQ/0BiwlCoVBkLGwZ\nal0CcE1tIyFELiGEY9LfmNbTOPzivRQKRUYiLX0Qt3jcB2GHaYXv4WnQdgX+Nj8FcAB+l1KuefEu\nCoUiI/HCBCFMn+7KmHwoARJlap0WZqSUZ837KhSKTMoLbzHMyWCVlDLB/GOczZFCochwpKUP4qAQ\nwjv1zRQKxf8bL/KkdJBSxgPewB4hxBkgGtMCOlJKWTWdYlQoFC+JF/VB7AaqAq+lUywKhSKD8aIE\nIcC0mlY6xWKYq7URA0uSMGo8zMO4RGOEgXy5jBncNbennyG6PefqNs/vGda9q4+/w9NcscHjIq3k\nzGbc9fw0L6rJWQhhcfKAlPJ7A+JRKBQZiBclCHsgN+aWhEKh+O/xogQRKaUcnW6RKBSKDMeLHnOq\nloNC8R/nRQmiYbpFYSUJCQnUru5Dh7atMryu3i7DKblz+zbdu3SgmrcX1apWYPeuMJu13hvUjypl\nitKw5rNPr3+a8gNFC2Tn5o0oq3WNdMzu6OfGwr5+LOrnRyc/k1v2m3WL83sfX37r48vkTpVwym2b\nCU0SlcqWpKZfFQKq+VC/ljarwMiIcLq3a07Luj60rOfLr7NMNgLfjP6EFgHetG5YjUG9OnJXg5O6\n3i7qFhOElPKmJmUD+XHKJDw9y2YKXb1dhlPy0bChNGzclF0HjrB15348PW03R2nfOYh5i5c/U345\n/BJbNobi5l7UJl2jHLNLOufi9SpF6P7LPjrP3Etts1v2vLBLdJ61ly6z9rLt1A36BBS3Ke6UrFgd\nytZd+9i4fVfqG78AewcHPhj5FcGb97EoeCO/z5nJ6ZPHqFmnAcs37mHZ+l0U9yjNjMnWe1gkobeL\neqZbOCciPJyQNavopsEEIz119XYZTuLunTvs2L6VoO69AMiaNasmw5HqNZ91+Ab4/JMP+OTzsTZb\n7xnlmF28YE4OX77LoxRu2fU9nYhOsVBzjqz2ZKTZAS6uhfCq9PhYlCzlydXISGrVa5jspF7Zx4+r\nkba7nuvtop7pEsTwYUMZ/eU47Oz0Dd0oXaO4cP4cTk5ODOrfm7o1fBkyoB/R0foawYSsWkGhwkUo\nX6GSLnp6OmafuR5NlaJ5yZvDgWwOdtQsWQDXPKa1nd6qV4LgwdVp5uXKT1vOa4pZCEHbVs2pV9Of\nObNnatJKScSlCxw7fIjKVZ+0av1rwTwCGjTRpQ49XNQN/TQIIfIJIZYIIY4LIY4JIWpo0VuzKhhn\nFxe8q/roFaKhukYSnxDPoYMH6Nm3P5vD9pIzZy5++G68bvoPYmKY8v3XvPfxSF309HbMPn8jhl/D\nLjK5U2UmdarEyav3SRpj9+Omc7ScvJM1R67SwddNU9yrQzezOWwPi5cGM2vGj2zfpt3vKDr6PkP6\ndGH46PHkdnzscD594tfYO9jTqm3gC/ZOG3q5qBv9dTkRWCOlLItp6vcxLWI7w3awOngFFT096NWt\nM1s2baRvzyDNQRqlayRFirhTxM0dXz/Tt0PrNm355+AB3fTPnz/LpYvnaRrgR43KZYi8HEHzetW5\ndvWK1VpGOWYvP3SFbj/vo/+8g9x7GM/FmzFPvL/68FUaeDpbrZuSIm6mBOPs4kLLVq3Zv1ebrV5c\nXBxv9+lCq7aBNGnROrn870Xz2RS6hm+m/KzZSV1PF3XDEoQQIi9QB5gNIKWMlVJqWuhy1JixHDtz\nkX9PnOXnX3+nTr36zPxlnuZYjdI1EtdChXBzd+fUyRMAbN60Ac+y+jk4lytfgYMnLxF26CRhh05S\nuIgbqzftxMXscp1WXuSYnYStjtn5zX6grnmyUd/TmTWHr1HUvKwfQN0yTpy/EWNp91SJjo7m3r17\nyX9vWL+OcuW9bNaTUjLivQF4lPakR//Hx2LrxnXMnjaBaXMWaXZS19tF3chB3SWA68AvQojKwD7g\nbSnlEzfKT7haF32xq3VmRG+X4ZSM/3Yi/Xt1IzY2luIlSjBl+mybtQb2CWLn9q3cvBGFn1dJ3hs+\ngo5BPTXHaKRj9vg3vJLdsr8OOcn9R/F82tKTVwrkJFFKrtx9yFer07TG03O5fu0qXTu2AyAhPp43\nOnSkUZNmNuvt3x3G8iULKFPOizaNTHfb73w0irGfDiP20SN6B5rmRVb28WPUeNscxPV2UU/V1dpW\nhBC+wE6glpRylxBiInBXSvmppX28fXzl5u27DYnHKLLYGzOezMjJWtE62M4/j9vRxriHq8laT1K0\noPb1Wp4moMbzXa2N7IMIB8KllEkPj5dgmj6uUCgyCYYlCCnlFUzreiYtidwQ0Gfde4VCkS4YPbF8\nMPCbECIrcBbQflOrUCjSDUMThJTyIKDLor0KhSL9yRzDBhUKxUtBJQiFQmERlSAUCoVFVIJQKBQW\nUQlCoVBYJP38s9OChEQDRnZGPzRm5CBALoMs9TXO13khDgZ59Rtlp/9V2wqG6ALM2XPBEN3GJV0M\n0QXjllp4bl3pV5VCochsqAShUCgsohKEQqGwSMbqg0gDlcqWJLejI/Z29jg4OGgyEn1vUD9C167G\nycmZ9Tv2A/DNl6MIWR2MnZ0dTk7OfD91JoUKF8kwMRulO3RgP9aFrMLJ2ZlNYSbjmRVL/+TbcWM4\ndeI4qzZsp4q39Y5b7w3qx/q1qymY4hgn8dOUH/hi5HAOnQqnQEEnq3RjHz3k3W6vERcbS0J8PAFN\nWtF98Icc2LmVGd98RnxcHKW9KvHemInYO1h3mY8OrEP2HLkQ9vbY2dvz3oxlzB01mGuXzgHw4P5d\ncuTOw7DZwVbpRl4O5+O3+3Ej6hpCCNp17klQnwHJ78/5aRLfjvmErf+cI38B645HEv379mLNqpU4\nO7uw9+C/NmmkJNMlCDC5DBd0su0ApqR95yB69H2Ld9567M/w5uB3GfbJKABm/zSVH74Zy7jvp2iu\nS6+YjdLt0DmInn3fYshbvZLLPMuVZ/a8RXzwziCbdZ93jEG7W3aWrNn45ue/yJErN/FxcQzt2hLf\n2vX55uNBfP3zX7gXL8mcyeNYu2whzd/oarX+gB9+I3e+x2bD3UdNTv572dSxZM/laLWmg70Dw0aO\npXzFKkTfv0eH5gHUrNOAkmXKEnk5nB1bNlDYzbbjkURQtx68OWAQfXt216STxH/6FuN5Ts6OKfz7\nHsREa7b/yizUqBVA/qeORRnPcpQq7Wlhj7RhlFu2EIIcuXIDEB8fR3x8HHZ29jhkyYp78ZIA+NSo\ny9a11n3Lp4aUkoMbV1K1UUur933a4duj9GOH769HDefdT8Zovt70dlHPdAnCKJfhlIz/YiR+FUry\n9+KFvP+RdtNWo2JOj2NhBHq5ZSckJNC/TT3a1y5H1Zr1KFupKgnx8Zw4fBCALWtXcN0Gi32BYPr7\nPfiu72vsWL7giffO/rOH3AWccHYvoSl2k6u1yeF7Q0gwLoWKULa8/osracWwWwyzD8SiFEUewEgp\n5Q9adFeHbqaImxvXr12jTatmlPb0pFbtOppifZoPR4zmwxGjmTLha36Z+aPmJGFUzOlxLPQmyS37\nt7+0f7Pb29vz09+buH/3DqOGdOf86eN88t0Mpo8bQVxcLD4169m0jMHgKYvI51yIe7eimP5ed1xf\nKUnJyv4A7A9dQdWG2lZei4m+z9B+JodvewcHZk7+jhm/L9WkaRRGGsackFJWkVJWAXyAGOBvrbp6\nuwy/iDbtO7J6hfYTZ1TM6Xks9EJPt+wkcufJS2X/2uzduoHyVfyYMD+YKYvWUtG3RvLthjXkczYZ\n8zrmd6JiQBMuHjsEmHwp/9kagnf9V22ONS4ujnf6deXVNh1o3KI1l86fI+LSed5oUpMm1b24GhlB\n+2YBRF27anMdepJetxgNgTNSSk3D1vR2GX4eZ8+cTv47ZFUwJTXegxsVc3ocCyPQyy379s0o7t+9\nA8Cjhw/Yv2MTRT1Kc+vGdQBiYx+xaNZkWgb2sEr30YMYHsbcT/77xJ6tFCpRBoCT+7bjWqwk+VwK\nW6WZhJSSke8PxKPUY4fvMuW82HLoHGt3HmHtziO4FnZj8ZqtOLm42lSH3qTXU4yOwIJUt0oFvV2G\nB/YJIszs5OxrdnLesC6Es6dPIuzscC9ajK++m5y6UDrGbJTuW72D2LFtCzdvRFG1vAfvD/+UfPkL\nMOLDodyIuk5Qh9fxqliJhX+ttErXKLfsm9ev8vVHg0hMTEQmJlKnWWuq12vCjG9GsXPzWmRiIq06\n9sC7unWmtPduRfHLiLcAUx+HT6NWlKtWF4ADG4Lx1nB7kdLh+40mJofvtz/8jDoNrVuX9EXo7aJu\nmKt1cgUmu7nLgJeU8pl2U0rbe/eixXz+PXFW9xgy41wMI3mYYv1KPYlPNOZaOn7lniG6AIev3zVE\n18i5GB4uuXTXrFU9/V2tk2gO7H9ecgCQUs6QUvpKKX2dnLStgqRQKPQlPRJEJ3S4vVAoFOmP0Yv3\n5gIaA38ZWY9CoTAGo12to4GCRtahUCiMI9ONpFQoFOmHShAKhcIiKkEoFAqLqAShUCgsohKEQqGw\nSIYaBigEZLHXP2clGDhY1Ih4AewNtC6+cvuhIboJBo2kLJgzqyG6AL38ixui+2PYOUN0AQY5exim\n/TSqBaFQKCyiEoRCobCIShAKhcIiKkEoFAqLZKoEEX7pEs2bNMCnshe+VSowdfJETXrvD+5HVc+i\nNK5VNblswvgx+Ht50LyuP83r+rNh3ZoMFXNK1oasoZKXJ15lS/HN1+Ns1omMCKd7u+a0rOtDy3q+\n/DprKgDfjP6EFgHetG5YjUG9OnL3zm3rtS+H07N9C16r70vrBn7MmzXtiffn/DSJCu6O3LoZZZXu\nlcvh9OvYkjca+dOucTV+//lHAE4e/ZfubRrRoWkN3u4dyP172qdzJyQkULu6Dx3aarOaAxjXqS4T\nerdgYt9WTH7zdQAunznGtEHtmNC7BXM+7svDaNunt+t9vWWopxip4eDgwFfjv6WKd1Xu3btHQHVf\nGjRqTLly5W3Sa98piO593uLdAU8aavR+azD9Bw3VI2TdY04iISGBd4YMZOXqdbi5u1O7uh8tW75G\nufLW69o7OPDByK/wqmSyY3+jmcmOvWadBgz9+HMcHBz49otPmTH5O94fMcYqbaOs3u0dHBg64gvK\nVTDpdmlVl+oB9Rk9fDBDP/4Cn+q1WfrHPH6dMYkB742wWj8lP06ZhKdnWe7pkGwA+n0/n1x5HztP\n//Xtx7R4czgelauxZ/VitiyaRZNetl1/el9vmaoFUahwYap4m77tHR0d8SxbjsiICJv1qlmwZNcT\nvWNOYs/u3ZQsWYoSHh5kzZqV9oEdCV6xzCYtF9dCeFV6bMdespQnVyMjqVWvIQ7mRWcq+/hxNdL6\nuI2yend2KUS5Co91S5T05NqVy1w8d4aq1WoBUL12fdavXm61dkoiwsMJWbOKbhpcmVLjevg5SlQy\nmeKW9qnF4a22t1r1vt4yVYJIyYXz5zl06AC+/tV01/511o80DfDl/cH9uHP7lm66esZ8+XIE7ikW\nnXFzcydCh8RjsmM/ROWqvk+U/7VgHgENmuigrb/V++VLFzhx9B8qVPHFo3RZNq012eKFrlpqU1JL\nyfBhQxn95Tib3LGfhxCC2cN6MLl/a3YFLwTA9ZXSHN0eCsC/m1dz+5rtBr4p0eN6M9oPYqgQ4ogQ\n4rAQYoEQIrseuvfv36dLx3aM/3YCeVIsdKMHXXv2Y8u+Y6zevBsX10KM+fRDXXSNjFkvoqPvM6RP\nF4aPHk9ux8cxTp/4NfYO9rRqG2iz9vOs3ge9/4nmmGOi7/P+W0G8N/Ircjvm4bOvp7J4/iw6t6xD\n9P37ZMmSxWbtNauCcXZxwbuq9UsOWuLNiQsZMmM5Pcf9TNjS+Zw9tJt2H4xj57L5TO7fmkcx0Tho\niDkJva43I9fFcAOGAOWllA+EEH9gMq+do0U3Li6OLoHtCOzYmdavt9Uh0idxTuEm3KlbL3p10l6H\nETEXKeJGePil5NcREeG4mW3wbSEuLo63+3ShVdtAmrRonVz+96L5bApdwy+Lgm1e9elpq/eTx44k\nW70DyVbvC4M3WeXmHBcXx/tvBtHi9Q40bPYaACVKlWHaPNNSBRfOnmbbxhCbYgbYGbaD1cErWLdm\nNQ8fPeTe3bv07RnEzF/m2ayZ12ypnzt/QbxqNyb8+D/UCexD72/mAnD90jmO79xksz7oe70ZfYvh\nAOQQQjgAOTGZ19qMlJIB/fvgWbYsg995V5cAn+bqlcjkv0NWLseznDYreaNi9vXz4/TpU5w/d47Y\n2FgWL1rIqy1fsznGEe8NwKO0Jz36D04u37pxHbOnTWDanEXkyJnTZm0jrN6llIz+cBAlSnnStc/j\ntUNvRpls7xMTE5k15Rve6NLLkkSqjBozlmNnLvLvibP8/Ovv1KlXX1NyiH0QwyOzpX7sgxhO7d2G\na4nS3L91IznmDfOnUu21TjbXoff1ZlgLQkoZIYT4FrgIPADWSinXPr1dSlfrosWKvVAzbMd2Fvw2\nD68KFanh5w3AqNFf0rR5C5tiHNzXZHt/60YU1SqUZOjwEezctoWjh/9BCIF7sVcY+522hXv1jjkJ\nBwcHJkycQqtXm5KQkED3Hr0o72VbMtu/O4zlSxZQppwXbRrVAOCdj0Yx9tNhxD56RO9AU+Kp7OPH\nqPGTrNI2yur94N6drPxrIaXKetGxeW0ABn0wkovnzvDHPNMyhA2atqJ1e+sX7jWKe7eimDfStJp3\nYkI8VRq+hqd/Xbb9OYedy+YD4FW7Cb7N2tlch97Xm2G290KI/MCfQCBwG1gMLJFSzre0T1UfX7k1\nTP/VoW7cj9VdM4mCuY2ZSGTkZK3z16MN0TVqslZsfKIhugAlXXMbomvoZK1a+k/WCqiR/rb3jYBz\nUsrrUso4TMa1NQ2sT6FQ6IyRCeIiUF0IkVOYercaAscMrE+hUOiMkYv37gKWAPuBf811zTCqPoVC\noT9G295/BnxmZB0KhcI4Mu1ISoVCYTwqQSgUCouoBKFQKCyiEoRCobCIShAKhcIiGcowRmDMCMLR\noad010xichttczVeBkUL2javIjWMGv1p1AhNMC7mgTVLGKIL4DFgie6aNy8+39ZAtSAUCoVFVIJQ\nKBQWUQlCoVBYJNMlCL2cnF0dszKyccnkn8ltytGodEHaVXJlTLPSjGpSigE1i5Eji7ZD1L9vL15x\nc8W3inZrtafR61ikJZCXeQAACxxJREFUxEgXbsh8MRsRL8DDhw+pV7s6Nfy88fOuyJejR1m1/w89\nfDnyfSs2f/7YBrCVjzubP29C5Ix2VH7lsddq/lxZ+ev9upyd0oaxnb2tqidTJYgkJ+dlK1Zz4J+j\nLF64gGNHj9qkdfVeLKPXnWH0ujOMCT1DbHwi+yPucvRqNJ+FnGLU2tNcvf+IFuWcNcUc1K0HS4NX\na9J4Hnoei5QkuSLvO3SEjVvDmDl9GseOadeFzBezUfECZMuWjeA1oYTtOcCO3fsJXRfC7l0707z/\nwu3n6fjD1ifKjl++Q69pOwg7df2J8kdxCYxbephRiw9ZHWemShB6OjmnpJxLbq5Hx3IzJo6jV++T\n1Gl+9kYM+XNo8wesHVCHAvkLpL6hlRh1LIxy4YbMF7NR8YLJvDZ3bpMXRVxcHHFxcVZZ+u08FcXt\n6Cd9Tk5F3uPM1fvPbBsTm8Du0zd4FJdgdZyZKkEY5eTsXywvuy7eeaa8don8HI60fRETIzHqWKRE\nb+fwzBaz0fEmJCRQ078qHkULUb9hI/wMcGjXitGu1m+bHa2PCCHeMbIuW7G3E1Qu4si+S08miFfL\nOZOQCDufkzj+C2QGF+6nyWwx29vbs2P3fo6fuci+PXs4euTwyw7pGQxLEEKICkBfwB+oDLQUQpTS\noqm3kzNAxUK5uXjrIXcfPW5+1Syej0qFHZm169IL9ny5GHEskjDKOTyzxWxkvCnJly8fderWY91a\n2x24jcLIFkQ5YJeUMkZKGQ9sBjSdOT2dnJPwL5aX3RcfrznpVSg3zTydmLz9ArEJxo3g04oRxwKM\ndQ7PbDEbFS/A9evXuX3bdN09ePCADetDKePpqYu2nhg51Pow8KUQoiAmV+sWwN6nN7LG1VpPJ2eA\nrPaC8q65mbfvsRt/F+/CONjb8W6d4gCcvfmA+ftsd+vv3rUzW7Zs4kZUFKVKFGXEyFH00GEZN72P\nRRJGuXBD5ovZqHjBtLxC/z49SUhIIDExkbZvtKd5i5Zp3n9632rU9HSmQO5sHPj6Vb5ZfoRb0bGM\n7eRNQcds/PZ2bQ5fvJ38pGPPuBY45shCVns7mlcpQuCELZxMQ/+aYa7WAEKI3sAAIBo4AjySUlrs\ni/Dx8ZXbdz2TQzQz6C/j7u2Mmoth6yI1acGouQ1qLsZj4hMMdOIe+KfumjeXDSfu+pl0dbVGSjlb\nSukjpawD3AJOGlmfQqHQF0NncwohXKSU14QQxTD1P1Q3sj6FQqEvRk/3/tPcBxEHDJRS3k5tB4VC\nkXEw2tU6wEh9hUJhLJlqJKVCoUhfVIJQKBQWUQlCoVBYRCUIhUJhEZUgFAqFRQwdSWktQojrwIU0\nbu4ERBkQRmbTNVI7s+kaqf3/rvuKlPIZd6QMlSCsQQixV0rp+1/XNVI7s+kaqf1f1VW3GAqFwiIq\nQSgUCotk5gQxQ+karp3ZdI3U/k/qZto+CIVCYTyZuQWhUCgMRiUIhUJhEZUgFAqFRYz2g9AFIURZ\noDWQZCkcASyXUh57eVG9HIQQ/oCUUu4RQpQHmgHHpZSrdK7nVyllNz01/+sIIbICHYHLUspQIURn\noCZwDJghpYx7qQE+hwzfSSmE+BDoBCwEws3F7pgO9EIppX4LJuqIOam5YXL2vp+ivJmUco2Nmp8B\nzTEl9nVANWAj0BgIkVJ+aaPu8qeLgPrABgAppT5Wzqa6amNaCuGwlHKtBp1qwDEp5V0hRA5gOFAV\nOAqMlVLavKCJ+F97ZxtiRRXG8d/fXVPXXV8isyx1fcksLZdMkYxcKvZD9iJkH6xITTSNUosEQaOC\nosCgiIqyRBGzF0sjitIwypc0ldVdFV8WV5PIbL+kpoZoTx/OszFe7tX1zl1w1/ODYc49Z+b/nJk7\n95lzzn3OjDQdWGFmBX3vgaSPCN9dCfAXUAosB+4i/BbHp9DuS3hqW0/gDOHxjkvN7GiqSpvZRb34\ngbbNkn8ZUNeMdiem2Hc6sAf4EjgAPJAoq06hux0oIlxgR4FOnt8BqE2hWw0sASqBUb4+5OlRKc/j\npkR6MrANeAFYD8xOobsTKPb0fOBN4HbXXp6yzkeA34G1hIcudyvQNVXr62LgMFDkn5Xy+5sOrALm\nAj8D7wCvEJxlZao6F+LAm3MBdhPixDPzewN7mtHuwRT7bgdKPV1OeNz/DP+8NYXu1mxp/7wthW4b\n4BlCq6TC8+oLdB6Tdd7c+GMDOgLbU+juSqSrM8ryPheNdfZzUgUsABqA74DxQFkK3R2EG1tX4Bhw\nuee3Tx5Pntdbo7MpAX70dK8015uZtYgxiJnAakl1QGOTrxfQH3gqjbCk2lxFQPcU0m3MuxVmdkBS\nJfC5pN6unS+nJJWY2Qlg6P+VlToDeT9n3cz+Bd6QtMzXhync+FQbSV0JPziZWYPbPC7pdArdHZIm\nmtlCoEbSrWa2RdIAwjNQ02B+TlYBqyS1JXTtxgGvA/m+8n0B4YZXBMwBlkmqJzzM+ZOUdS4mdC3a\nEboumNlBr3v+FOIu0dwL4eIaATzoywjcY6bUPQxUEFojyaWcMJCUr+4P+J04kVcMLAbOpNBtlyP/\nCuCmAp7v0YR+fCG0DgD1wH5fX+35paRr9XQGFgH7gF8ITqGe8Aa3ISnrnPOuC5Sk1O4B9PB0F2As\nMDyl5gygFviA4IAmen43YE0a7Yt+kLI5kbQAWGhm67KULTWzh/PUvRY4bWZ/ZCkbaWbr89FtTUgq\nAbqb2f6UOp2APgQH/JuZHS5A3QaYWYt6h4ukQYTXXe4ws90F072UHUQkEjk3MVAqEonkJDqISCSS\nk+ggWiiSzkjaJmmHpGXep89Xq1LS156+X9Lsc2zbRdKTedh4UdJzTc3P2GaRpLEXYKtcUvO9sfkS\nIjqIlstJM6sws8HAKWBqslCBC/5+zewrO3d0ahdC8FDkEiA6iNbBWqC/3zn3SFpMCMrpKalK0gZJ\n1d7SKIUQ8i1pt6RqQogunj9B0tue7i5phaQaX24DXgP6eetlnm83S9JmSbWSXkpozZG0V9I64Prz\nHYSkya5TI+mLjFbR3ZK2uN69vn2RpHkJ20+kPZGRs4kOooUjqZgQxLPds64D3jWzQcBxQvjt3WZ2\nCyGi81lJ7Qn/md9HCLi6Kof8W8BPZjaEMM9hJ2HOwz5vvcySVOU2hxNiSoZKukPSUMJ8mQrgHmBY\nEw5nuZkNc3u7gEmJsnK3MRp4z49hEnDEzIa5/mRJfZpgJ9JEWkIkZSQ7HSRt8/RaQpReD+BXM9vo\n+SOAG4H1kiCE+W4ABgL7zawOQNISYEoWG3cCjwGY2RngiEdFJqnyZat/LiU4jDLChKcTbiNzQlg2\nBkt6mdCNKQVWJso+sxDdWOfRhwPd7s2J8YnObrtFxTBczEQH0XI5aWYVyQx3AseTWcD3ZjYuY7uz\n9kuJgFfN7P0MGzPz0FoEjDGzGkkTCJPGGskM2DG3/bSZJR0JksrzsB3JQuxitG42AiMl9QeQ1NHn\nKuwGyiX18+3G5dh/NTDN9y3yOR/HCK2DRlYCjyfGNq6RdCWwBhgjqYOkMkJ35nyUAYd8/sAjGWUP\nSWrjde5LmC27EpjWON9A0gBJHZtgJ9JEYguiFWNmDX4n/lhSO8+ea2Z7JU0BvpF0gtBFKcsiMQOY\nL2kSYSLQNDPbIGm9/434rY9D3ABs8BbM38CjZlYt6VOgBviTMJPzfDxPmFfR4OtknQ4Cm4BOwFQz\n+0fSh4SxiWoF4w3AmKadnUhTiKHWkUgkJ7GLEYlEchIdRCQSyUl0EJFIJCfRQUQikZxEBxGJRHIS\nHUQkEslJdBCRSCQn/wHj5LNtIKyhCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature maps visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUJXjFYSpZWI"
   },
   "outputs": [],
   "source": [
    "# Visualize feature maps\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model_gpu, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "# 1st layer feature map picture 1\n",
    "model_gpu.layer1.register_forward_hook(get_activation('layer1'))\n",
    "data, _ = ins_dataset_train[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer1'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "  axarr[0,0].imshow(act[0], cmap='gray')\n",
    "  axarr[0,1].imshow(act[1], cmap='gray')\n",
    "  axarr[1,0].imshow(act[2], cmap='gray')\n",
    "  axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 1')\n",
    "\n",
    "\n",
    "\n",
    "# 2nd layer feature map picture 1\n",
    "model_gpu.layer2.register_forward_hook(get_activation('layer2'))\n",
    "data, _ = ins_dataset_train[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer2'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "  axarr[0,0].imshow(act[0], cmap='gray')\n",
    "  axarr[0,1].imshow(act[1], cmap='gray')\n",
    "  axarr[1,0].imshow(act[2], cmap='gray')\n",
    "  axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 2')\n",
    "\n",
    "\n",
    "# 3rd layer feature map picture 1\n",
    "model_gpu.layer3.register_forward_hook(get_activation('layer3'))\n",
    "data, _ = ins_dataset_train[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer3'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 3')\n",
    "\n",
    "# 4rth layer feature map picture 1\n",
    "model_gpu.layer4.register_forward_hook(get_activation('layer4'))\n",
    "data, _ = ins_dataset_train[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer4'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 4')\n",
    "\n",
    "# 5th layer feature map picture 1\n",
    "model_gpu.layer5.register_forward_hook(get_activation('layer5'))\n",
    "data, _ = ins_dataset_train[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer4'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 5')\n",
    "###############################################################################\n",
    " picture 2\n",
    "\n",
    "# 1st layer feature map picture 2\n",
    "model_gpu.layer1.register_forward_hook(get_activation('layer1'))\n",
    "data, _ = ins_dataset_train[1]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer1'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 1')\n",
    "\n",
    "# 2nd layer feature map picture 2\n",
    "model_gpu.layer2.register_forward_hook(get_activation('layer2'))\n",
    "data, _ = ins_dataset_train[3]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer2'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 2')\n",
    "\n",
    "# 3rd layer feature map picture 2\n",
    "model_gpu.layer3.register_forward_hook(get_activation('layer3'))\n",
    "data, _ = ins_dataset_train[3]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer3'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 3')\n",
    "\n",
    "# 4rth layer feature map picture 2\n",
    "model_gpu.layer4.register_forward_hook(get_activation('layer4'))\n",
    "data, _ = ins_dataset_train[3]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer4'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 4')\n",
    "\n",
    "# 5th layer feature map picture 2\n",
    "model_gpu.layer5.register_forward_hook(get_activation('layer5'))\n",
    "data, _ = ins_dataset_train[4]\n",
    "data.unsqueeze_(0)\n",
    "output = model_gpu.cpu()\n",
    "output = output(data)\n",
    "\n",
    "\n",
    "act = activation['layer4'].squeeze()\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[0,0].imshow(act[0], cmap='gray')\n",
    "    axarr[0,1].imshow(act[1], cmap='gray')\n",
    "    axarr[1,0].imshow(act[2], cmap='gray')\n",
    "    axarr[1,1].imshow(act[3], cmap='gray')\n",
    "fig.suptitle('Feature map layer 5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AI_Coursework1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
